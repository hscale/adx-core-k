# Deployment Monitoring Configuration
# This file defines monitoring rules and alerts for ADX Core deployments

apiVersion: v1
kind: ConfigMap
metadata:
  name: deployment-monitoring-config
  namespace: adx-core-monitoring
data:
  prometheus-rules.yml: |
    groups:
    - name: deployment.rules
      rules:
      # Deployment Success Rate
      - alert: DeploymentFailureRate
        expr: |
          (
            rate(deployment_failures_total[5m]) / 
            rate(deployment_attempts_total[5m])
          ) > 0.1
        for: 2m
        labels:
          severity: warning
          component: deployment
        annotations:
          summary: "High deployment failure rate detected"
          description: "Deployment failure rate is {{ $value | humanizePercentage }} over the last 5 minutes"

      # Service Health After Deployment
      - alert: ServiceUnhealthyAfterDeployment
        expr: |
          (
            up{job=~"adx-core-.*"} == 0
          ) and on(instance) (
            increase(deployment_completed_total[10m]) > 0
          )
        for: 1m
        labels:
          severity: critical
          component: deployment
        annotations:
          summary: "Service unhealthy after deployment"
          description: "Service {{ $labels.job }} on {{ $labels.instance }} is down after recent deployment"

      # Response Time Degradation
      - alert: ResponseTimeDegradationAfterDeployment
        expr: |
          (
            histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2.0
          ) and on(instance) (
            increase(deployment_completed_total[15m]) > 0
          )
        for: 3m
        labels:
          severity: warning
          component: deployment
        annotations:
          summary: "Response time degradation after deployment"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.job }} after recent deployment"

      # Error Rate Spike
      - alert: ErrorRateSpikeAfterDeployment
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) / 
            rate(http_requests_total[5m])
          ) > 0.05 and on(instance) (
            increase(deployment_completed_total[15m]) > 0
          )
        for: 2m
        labels:
          severity: critical
          component: deployment
        annotations:
          summary: "Error rate spike after deployment"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }} after recent deployment"

      # Memory Usage Spike
      - alert: MemoryUsageSpikeAfterDeployment
        expr: |
          (
            (process_resident_memory_bytes / 1024 / 1024) > 1024
          ) and on(instance) (
            increase(deployment_completed_total[15m]) > 0
          )
        for: 5m
        labels:
          severity: warning
          component: deployment
        annotations:
          summary: "Memory usage spike after deployment"
          description: "Memory usage is {{ $value }}MB for {{ $labels.job }} after recent deployment"

      # Database Connection Issues
      - alert: DatabaseConnectionIssuesAfterDeployment
        expr: |
          (
            rate(database_connection_errors_total[5m]) > 0.1
          ) and on(instance) (
            increase(deployment_completed_total[15m]) > 0
          )
        for: 2m
        labels:
          severity: critical
          component: deployment
        annotations:
          summary: "Database connection issues after deployment"
          description: "Database connection error rate is {{ $value }}/sec for {{ $labels.job }} after recent deployment"

      # Temporal Workflow Failures
      - alert: TemporalWorkflowFailuresAfterDeployment
        expr: |
          (
            rate(temporal_workflow_failures_total[5m]) > 0.05
          ) and on(instance) (
            increase(deployment_completed_total[15m]) > 0
          )
        for: 2m
        labels:
          severity: warning
          component: deployment
        annotations:
          summary: "Temporal workflow failures after deployment"
          description: "Temporal workflow failure rate is {{ $value }}/sec for {{ $labels.job }} after recent deployment"

    - name: microfrontend.rules
      rules:
      # Micro-frontend Load Failures
      - alert: MicrofrontendLoadFailures
        expr: |
          rate(microfrontend_load_failures_total[5m]) > 0.01
        for: 2m
        labels:
          severity: warning
          component: microfrontend
        annotations:
          summary: "Micro-frontend load failures detected"
          description: "Micro-frontend {{ $labels.app }} has {{ $value }}/sec load failures"

      # Module Federation Errors
      - alert: ModuleFederationErrors
        expr: |
          rate(module_federation_errors_total[5m]) > 0.005
        for: 1m
        labels:
          severity: critical
          component: microfrontend
        annotations:
          summary: "Module Federation errors detected"
          description: "Module Federation errors for {{ $labels.app }}: {{ $value }}/sec"

      # CDN Cache Hit Rate
      - alert: CDNCacheHitRateLow
        expr: |
          (
            rate(cdn_cache_hits_total[10m]) / 
            rate(cdn_requests_total[10m])
          ) < 0.8
        for: 5m
        labels:
          severity: warning
          component: cdn
        annotations:
          summary: "CDN cache hit rate is low"
          description: "CDN cache hit rate is {{ $value | humanizePercentage }} for the last 10 minutes"

      # Frontend Performance Degradation
      - alert: FrontendPerformanceDegradation
        expr: |
          histogram_quantile(0.95, rate(frontend_page_load_duration_seconds_bucket[10m])) > 5.0
        for: 3m
        labels:
          severity: warning
          component: frontend
        annotations:
          summary: "Frontend performance degradation"
          description: "95th percentile page load time is {{ $value }}s for {{ $labels.app }}"

  grafana-dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "ADX Core Deployment Monitoring",
        "tags": ["adx-core", "deployment", "monitoring"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Deployment Success Rate",
            "type": "stat",
            "targets": [
              {
                "expr": "rate(deployment_successes_total[5m]) / rate(deployment_attempts_total[5m])",
                "legendFormat": "Success Rate"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percentunit",
                "min": 0,
                "max": 1,
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "yellow", "value": 0.9},
                    {"color": "green", "value": 0.95}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "Service Health Status",
            "type": "table",
            "targets": [
              {
                "expr": "up{job=~\"adx-core-.*\"}",
                "legendFormat": "{{ job }}"
              }
            ]
          },
          {
            "id": 3,
            "title": "Response Time After Deployment",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
                "legendFormat": "95th percentile - {{ job }}"
              },
              {
                "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
                "legendFormat": "50th percentile - {{ job }}"
              }
            ]
          },
          {
            "id": 4,
            "title": "Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
                "legendFormat": "Error Rate - {{ job }}"
              }
            ]
          },
          {
            "id": 5,
            "title": "Memory Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "process_resident_memory_bytes / 1024 / 1024",
                "legendFormat": "Memory Usage MB - {{ job }}"
              }
            ]
          },
          {
            "id": 6,
            "title": "Micro-frontend Load Performance",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(frontend_page_load_duration_seconds_bucket[5m]))",
                "legendFormat": "Page Load Time - {{ app }}"
              }
            ]
          },
          {
            "id": 7,
            "title": "Module Federation Status",
            "type": "table",
            "targets": [
              {
                "expr": "rate(module_federation_errors_total[5m])",
                "legendFormat": "{{ app }}"
              }
            ]
          },
          {
            "id": 8,
            "title": "Temporal Workflow Health",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(temporal_workflow_successes_total[5m])",
                "legendFormat": "Successful Workflows - {{ workflow_type }}"
              },
              {
                "expr": "rate(temporal_workflow_failures_total[5m])",
                "legendFormat": "Failed Workflows - {{ workflow_type }}"
              }
            ]
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: adx-core-monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@adxcore.com'
      smtp_auth_username: 'alerts@adxcore.com'
      smtp_auth_password: '${SMTP_PASSWORD}'

    route:
      group_by: ['alertname', 'component']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'default'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
      - match:
          component: deployment
        receiver: 'deployment-alerts'
      - match:
          component: microfrontend
        receiver: 'frontend-alerts'

    receivers:
    - name: 'default'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'ADX Core Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

    - name: 'critical-alerts'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#critical-alerts'
        title: 'üö® CRITICAL: ADX Core Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}
      email_configs:
      - to: 'oncall@adxcore.com'
        subject: 'CRITICAL: ADX Core Alert - {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Time: {{ .StartsAt }}
          {{ end }}

    - name: 'deployment-alerts'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#deployments'
        title: 'üöÄ Deployment Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Component:* {{ .Labels.component }}
          {{ end }}

    - name: 'frontend-alerts'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#frontend-alerts'
        title: 'üñ•Ô∏è Frontend Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *App:* {{ .Labels.app }}
          {{ end }}

    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'component']